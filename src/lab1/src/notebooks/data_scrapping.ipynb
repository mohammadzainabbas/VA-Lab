{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9618310d",
   "metadata": {},
   "source": [
    "# Web Scraping Tutorial\n",
    "\n",
    "This tutorial will teach you how to use Python to scrap and extract data from a web page. We will use two packages, `requests` to scrap the webpage and `BeautifulSoup` to extract the data.\n",
    "\n",
    "Many good references on web scraping are available online. I would recommend the following resources:\n",
    "1. Automate Boring Stuff with Python by Al Sweigart (2020) has a chapter on Web Scraping tutorial, which can be read [online](https://automatetheboringstuff.com/2e/chapter12/).\n",
    "2. Web Scraping With Python by Ryan Mitchell (2018) is a bit old book but provides a comprehensive guide to the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ed654",
   "metadata": {},
   "source": [
    "## Step 0: Getting to know the web page\n",
    "\n",
    "In this tutorial, we will try to extract the cryptocurrency market prices from the CoinGecko website https://www.coingecko.com/.\n",
    "\n",
    "Your first step should always be to familiarize yourself with the website you want to scrape. Take a look at the website and try to inspect the HTML elements on the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17dfa0c",
   "metadata": {},
   "source": [
    "## Step 1: Scrap a web page\n",
    "\n",
    "Now, we are ready to scrap a webpage we want to get the data from with the `requests` package. We will use the following functions:\n",
    "\n",
    "* `requests.get('URL')` - make a request to the specified URL\n",
    "* `r.status_code` - get the status code of the request\n",
    "* `r.content` - get the binary content of the page\n",
    "\n",
    "More functions in the `requests` package are available in [its documentation](https://requests.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4756eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will import the requests package\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request the webpage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the request we've got\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74151d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the header of the web page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the content of the web page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the content of web page to the local drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d01f8",
   "metadata": {},
   "source": [
    "## Step 2: Extract data from the web page\n",
    "\n",
    "After we crawled the web page and download it to the local disk, we will use `BeautifulSoup` package to parse HTML file and access the content. We will use the following functions:\n",
    "\n",
    "**1. Load the web page to BeautifulSoup**\n",
    "* `soup = BeautifulSoup(html_doc, 'html.parser')` - parse the HTML content to BeautifulSoup object\n",
    "\n",
    "**2. Get the content of the element**\n",
    "* `soup.title` - get the title of the page\n",
    "* `soup.title.string` - get the string in the title tag\n",
    "* `soup.h1` - get the H1 element in the web page\n",
    "* `soup.h1.attrs` - get all attributes in the H1 element\n",
    "* `soup.h1['class']` - get the class attribute in the H1 element\n",
    "\n",
    "**3. Look for the element in the web page**\n",
    "* `soup.find('HTML_tag')` - get the element from an HTML tag\n",
    "* `soup.find_all('HTML_tag')` - get the list of elelemts that has the specified HTML tag\n",
    "* `soup.select('CSS_selector')` - get the list of elements with the specified [CSS selector](https://www.w3schools.com/cssref/css_selectors.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2eef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will import the BeautifulSoup from bs4 package\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29460bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the web page and parse it to BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of our soup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all text in the web page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the title of the page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also get the page title using soup.find() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other HTML tags also work too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1fcbf",
   "metadata": {},
   "source": [
    "Now, we will extract the cryptocurrencies market price from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table element in the web page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are > 1 elements that match the tagged, \n",
    "# use soup.find_all() to retrieve all of them as a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe697d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over rows and get the data for each coin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726f336",
   "metadata": {},
   "source": [
    "## Step 3: Create data table and save as CSV file\n",
    "\n",
    "Let's wrap our data table as the pandas's DataFrame and save it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0f2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('visual_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae8dc205f4db5a1defeb3d03690316e6259ab9b9aea5e5b1523f70f76f6035e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
