{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9618310d",
   "metadata": {},
   "source": [
    "# Web Scraping Tutorial\n",
    "\n",
    "This tutorial will teach you how to use Python to scrap and extract data from a web page. We will use two packages, `requests` to scrap the webpage and `BeautifulSoup` to extract the data.\n",
    "\n",
    "Many good references on web scraping are available online. I would recommend the following resources:\n",
    "1. Automate Boring Stuff with Python by Al Sweigart (2020) has a chapter on Web Scraping tutorial, which can be read [online](https://automatetheboringstuff.com/2e/chapter12/).\n",
    "2. Web Scraping With Python by Ryan Mitchell (2018) is a bit old book but provides a comprehensive guide to the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ed654",
   "metadata": {},
   "source": [
    "## Step 0: Getting to know the web page\n",
    "\n",
    "In this tutorial, we will try to extract the cryptocurrency market prices from the CoinGecko website https://www.coingecko.com/.\n",
    "\n",
    "Your first step should always be to familiarize yourself with the website you want to scrape. Take a look at the website and try to inspect the HTML elements on the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17dfa0c",
   "metadata": {},
   "source": [
    "## Step 1: Scrap a web page\n",
    "\n",
    "Now, we are ready to scrap a webpage we want to get the data from with the `requests` package. We will use the following functions:\n",
    "\n",
    "* `requests.get('URL')` - make a request to the specified URL\n",
    "* `r.status_code` - get the status code of the request\n",
    "* `r.content` - get the binary content of the page\n",
    "\n",
    "More functions in the `requests` package are available in [its documentation](https://requests.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4756eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will import the requests package\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c15921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request the webpage\n",
    "url = \"https://www.coingecko.com\"\n",
    "res = requests.get(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ba2a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of the request we've got\n",
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb0b645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the status code\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74151d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Tue, 04 Oct 2022 08:44:29 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'CF-Ray': '754ca2ce0fee88bf-LHR', 'Age': '9', 'Cache-Control': 'max-age=30, public, must-revalidate, s-maxage=30', 'Vary': 'Accept-Encoding', 'CF-Cache-Status': 'HIT', 'Alternate-Protocol': '443:npn-spdy/2', 'Referrer-Policy': 'strict-origin-when-cross-origin', 'X-Content-Type-Options': 'nosniff', 'X-Download-Options': 'noopen', 'X-Frame-Options': 'SAMEORIGIN', 'X-Permitted-Cross-Domain-Policies': 'none', 'X-Request-Id': '113bb2a1-404b-4c06-a833-536da3e9a450', 'X-Runtime': '14.545432', 'X-XSS-Protection': '1; mode=block', 'Set-Cookie': '__cf_bm=Tloz8aIJhqO.No.EgCkocD1CgzgN4UbGPvgxufgaKwE-1664873069-0-AUO9MKKq1k0RmzT3w+yUU4KJ5EtRHzPuixQYWb33H6ff6ttBucTiLuhyuWLSF/2qZUXOICr/l7ny/xr8FrQdMas=; path=/; expires=Tue, 04-Oct-22 09:14:29 GMT; domain=.coingecko.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'Content-Encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the header of the web page\n",
    "res.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b8bf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n<script src=\"/cdn-cgi/apps/head/gYtXOyllgyP3-Z2iKTP8rRWGBm4.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the content of the web page\n",
    "res.content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5938e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the content of web page to the local drive\n",
    "\n",
    "with open(\"../data/coin_gecko.html\", \"w\") as f:\n",
    "    f.write(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d01f8",
   "metadata": {},
   "source": [
    "## Step 2: Extract data from the web page\n",
    "\n",
    "After we crawled the web page and download it to the local disk, we will use `BeautifulSoup` package to parse HTML file and access the content. We will use the following functions:\n",
    "\n",
    "**1. Load the web page to BeautifulSoup**\n",
    "* `soup = BeautifulSoup(html_doc, 'html.parser')` - parse the HTML content to BeautifulSoup object\n",
    "\n",
    "**2. Get the content of the element**\n",
    "* `soup.title` - get the title of the page\n",
    "* `soup.title.string` - get the string in the title tag\n",
    "* `soup.h1` - get the H1 element in the web page\n",
    "* `soup.h1.attrs` - get all attributes in the H1 element\n",
    "* `soup.h1['class']` - get the class attribute in the H1 element\n",
    "\n",
    "**3. Look for the element in the web page**\n",
    "* `soup.find('HTML_tag')` - get the element from an HTML tag\n",
    "* `soup.find_all('HTML_tag')` - get the list of elelemts that has the specified HTML tag\n",
    "* `soup.select('CSS_selector')` - get the list of elements with the specified [CSS selector](https://www.w3schools.com/cssref/css_selectors.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2eef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will import the BeautifulSoup from bs4 package\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29460bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the web page and parse it to BeautifulSoup\n",
    "with open(\"../data/coin_gecko.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f7ab9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the type of our soup object\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ee1f8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Cryptocurrency Prices, Charts, and Crypto Market Cap | CoinGecko                                                                                This website uses cookies for functionality, analytics and advertising purposes as described in our Privacy Policy. If you agree to our use of cookies, please continue to use our site.   OK                    Continue in app  Track prices in real-time   Open App                 Continue in app  Track prices in real-time   Open App               '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all text in the web page\n",
    "soup.get_text().replace(\"\\n\", \" \")[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae45ff28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Cryptocurrency Prices, Charts, and Crypto Market Cap | CoinGecko</title>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title of the page\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d370ecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASCII_SPACES',\n",
       " 'DEFAULT_BUILDER_FEATURES',\n",
       " 'DEFAULT_INTERESTING_STRING_TYPES',\n",
       " 'NO_PARSER_SPECIFIED_WARNING',\n",
       " 'ROOT_TAG_NAME',\n",
       " '__bool__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_all_strings',\n",
       " '_decode_markup',\n",
       " '_feed',\n",
       " '_find_all',\n",
       " '_find_one',\n",
       " '_is_xml',\n",
       " '_lastRecursiveChild',\n",
       " '_last_descendant',\n",
       " '_linkage_fixer',\n",
       " '_markup_is_url',\n",
       " '_markup_resembles_filename',\n",
       " '_most_recent_element',\n",
       " '_namespaces',\n",
       " '_popToTag',\n",
       " '_should_pretty_print',\n",
       " 'append',\n",
       " 'attrs',\n",
       " 'builder',\n",
       " 'can_be_empty_element',\n",
       " 'cdata_list_attributes',\n",
       " 'childGenerator',\n",
       " 'children',\n",
       " 'clear',\n",
       " 'contains_replacement_characters',\n",
       " 'contents',\n",
       " 'currentTag',\n",
       " 'current_data',\n",
       " 'declared_html_encoding',\n",
       " 'decode',\n",
       " 'decode_contents',\n",
       " 'decompose',\n",
       " 'decomposed',\n",
       " 'default',\n",
       " 'descendants',\n",
       " 'element_classes',\n",
       " 'encode',\n",
       " 'encode_contents',\n",
       " 'endData',\n",
       " 'extend',\n",
       " 'extract',\n",
       " 'fetchNextSiblings',\n",
       " 'fetchParents',\n",
       " 'fetchPrevious',\n",
       " 'fetchPreviousSiblings',\n",
       " 'find',\n",
       " 'findAll',\n",
       " 'findAllNext',\n",
       " 'findAllPrevious',\n",
       " 'findChild',\n",
       " 'findChildren',\n",
       " 'findNext',\n",
       " 'findNextSibling',\n",
       " 'findNextSiblings',\n",
       " 'findParent',\n",
       " 'findParents',\n",
       " 'findPrevious',\n",
       " 'findPreviousSibling',\n",
       " 'findPreviousSiblings',\n",
       " 'find_all',\n",
       " 'find_all_next',\n",
       " 'find_all_previous',\n",
       " 'find_next',\n",
       " 'find_next_sibling',\n",
       " 'find_next_siblings',\n",
       " 'find_parent',\n",
       " 'find_parents',\n",
       " 'find_previous',\n",
       " 'find_previous_sibling',\n",
       " 'find_previous_siblings',\n",
       " 'format_string',\n",
       " 'formatter_for_name',\n",
       " 'get',\n",
       " 'getText',\n",
       " 'get_attribute_list',\n",
       " 'get_text',\n",
       " 'handle_data',\n",
       " 'handle_endtag',\n",
       " 'handle_starttag',\n",
       " 'has_attr',\n",
       " 'has_key',\n",
       " 'hidden',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'insert_after',\n",
       " 'insert_before',\n",
       " 'interesting_string_types',\n",
       " 'isSelfClosing',\n",
       " 'is_empty_element',\n",
       " 'is_xml',\n",
       " 'known_xml',\n",
       " 'markup',\n",
       " 'name',\n",
       " 'namespace',\n",
       " 'new_string',\n",
       " 'new_tag',\n",
       " 'next',\n",
       " 'nextGenerator',\n",
       " 'nextSibling',\n",
       " 'nextSiblingGenerator',\n",
       " 'next_element',\n",
       " 'next_elements',\n",
       " 'next_sibling',\n",
       " 'next_siblings',\n",
       " 'object_was_parsed',\n",
       " 'open_tag_counter',\n",
       " 'original_encoding',\n",
       " 'parent',\n",
       " 'parentGenerator',\n",
       " 'parents',\n",
       " 'parse_only',\n",
       " 'parserClass',\n",
       " 'parser_class',\n",
       " 'popTag',\n",
       " 'prefix',\n",
       " 'preserve_whitespace_tag_stack',\n",
       " 'preserve_whitespace_tags',\n",
       " 'prettify',\n",
       " 'previous',\n",
       " 'previousGenerator',\n",
       " 'previousSibling',\n",
       " 'previousSiblingGenerator',\n",
       " 'previous_element',\n",
       " 'previous_elements',\n",
       " 'previous_sibling',\n",
       " 'previous_siblings',\n",
       " 'pushTag',\n",
       " 'recursiveChildGenerator',\n",
       " 'renderContents',\n",
       " 'replaceWith',\n",
       " 'replaceWithChildren',\n",
       " 'replace_with',\n",
       " 'replace_with_children',\n",
       " 'reset',\n",
       " 'select',\n",
       " 'select_one',\n",
       " 'setup',\n",
       " 'smooth',\n",
       " 'string',\n",
       " 'string_container',\n",
       " 'string_container_stack',\n",
       " 'strings',\n",
       " 'stripped_strings',\n",
       " 'tagStack',\n",
       " 'text',\n",
       " 'unwrap',\n",
       " 'wrap']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the page title using soup.find() function\n",
    "dir(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other HTML tags also work too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1fcbf",
   "metadata": {},
   "source": [
    "Now, we will extract the cryptocurrencies market price from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table element in the web page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are > 1 elements that match the tagged, \n",
    "# use soup.find_all() to retrieve all of them as a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe697d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over rows and get the data for each coin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726f336",
   "metadata": {},
   "source": [
    "## Step 3: Create data table and save as CSV file\n",
    "\n",
    "Let's wrap our data table as the pandas's DataFrame and save it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0f2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('visual_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae8dc205f4db5a1defeb3d03690316e6259ab9b9aea5e5b1523f70f76f6035e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
